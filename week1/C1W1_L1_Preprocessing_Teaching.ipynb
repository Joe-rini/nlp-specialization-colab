{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joe-rini/nlp-specialization-colab/blob/main/week1/C1W1_L1_Preprocessing_Teaching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb0e406-39d8-4aeb-8970-e29d071cb51a",
      "metadata": {
        "id": "7bb0e406-39d8-4aeb-8970-e29d071cb51a"
      },
      "source": [
        "\n",
        "# Lesson L1 ‚Äì Natural Language Preprocessing üåü‚úÇÔ∏èüßπ\n",
        "\n",
        "Welcome to **Lesson 1** of the *NLP Specialization Teaching Edition*.\n",
        "\n",
        "In this hands-on notebook, you‚Äôll learn how to clean raw text to prepare it for both classical ML and modern neural networks. The exercises and general set of ideas covered here is similar to the course, but you will find the demos and exploration intuitive and easy to grasp - you might find you don't need to try the course at all in order to learn the concepts :)\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Why does preprocessing matter?\n",
        "Raw text is **messy** ‚Äì full of punctuation, contractions, emojis, and hyperlinks.  \n",
        "Preprocessing helps your model **focus on the signal**:\n",
        "\n",
        "- ‚úÖ Smaller vocabulary  \n",
        "- ‚úÖ More consistent word forms  \n",
        "- ‚úÖ Faster, more accurate models\n",
        "\n",
        "---\n",
        "\n",
        "## üó∫Ô∏è What you‚Äôll do\n",
        "\n",
        "1. Run a **step-by-step walk-through** of one tweet.\n",
        "2. **Explore the full Twitter dataset** used in this course.\n",
        "3. **Wrap a preprocessing pipeline** into a reusable function.\n",
        "4. **Play with a Gradio app** to see it all in action.\n",
        "\n",
        "> üëâ Run each cell, tweak the code, and break things! That‚Äôs the best way to learn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece5b4cc-cef7-478a-a6f3-c1bdd459ddf6",
      "metadata": {
        "id": "ece5b4cc-cef7-478a-a6f3-c1bdd459ddf6"
      },
      "source": [
        "## üçÄ Step 0 ‚Äì Setup and Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91b469da-4911-4851-ad55-7a54be1978d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91b469da-4911-4851-ad55-7a54be1978d8",
        "outputId": "1320fec7-78c6-40e4-89f7-f1ee0c233723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.2 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.1.post1 which is incompatible.\n",
            "google-genai 1.25.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m‚úÖ Setup complete\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q --upgrade numpy==1.26.4 scikit-learn==1.4.1.post1 nltk==3.8.1 gradio==4.27.0 --progress-bar off\n",
        "\n",
        "import nltk, re, string, random\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download NLTK resources\n",
        "for res in ['stopwords', 'twitter_samples', 'punkt']:\n",
        "    nltk.download(res, quiet=True)\n",
        "\n",
        "print(\"‚úÖ Setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01aa24e-d234-4bf6-9405-1b9d5d13fc55",
      "metadata": {
        "id": "c01aa24e-d234-4bf6-9405-1b9d5d13fc55"
      },
      "source": [
        "## 1Ô∏è‚É£ Toy example ‚Äì step-by-step preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a4b4915-bdc4-480a-a5bd-85bb12b721a4",
      "metadata": {
        "id": "8a4b4915-bdc4-480a-a5bd-85bb12b721a4"
      },
      "source": [
        "\n",
        "Let‚Äôs warm up with one short sentence and manually walk through:\n",
        "\n",
        "1. **Tokenization**\n",
        "2. **Stop‚Äëword and punctuation removal**\n",
        "3. **Stemming**\n",
        "\n",
        "So you can *see* the effect of each transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aa83bea0-02c0-46e3-9fb1-72b86e6d7f16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa83bea0-02c0-46e3-9fb1-72b86e6d7f16",
        "outputId": "0863c650-7c83-4d8d-daae-3f4e4b63fb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî∏ Original sentence:\n",
            "I love Natural Language Processing! :) #NLP\n"
          ]
        }
      ],
      "source": [
        "#Take a single Tweet and work through the process of cleaning it.\n",
        "sentence = \"I love Natural Language Processing! :) #NLP\"\n",
        "\n",
        "print(\"üî∏ Original sentence:\")\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Tokenization: covert the individual words and symbols into individual tokens.\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(\"\\nüîπ After tokenization:\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "jE96AIfTN5wB",
        "outputId": "98f2ed06-ddd8-4aa9-9177-0518370a63b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jE96AIfTN5wB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ After tokenization:\n",
            "['i', 'love', 'natural', 'language', 'processing', '!', ':)', '#nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Stop-word & punctuation removal: remove useless words and punctuation using existing best practice lists\n",
        "stopwords_en = stopwords.words('english')\n",
        "tokens_no_sw = [w for w in tokens if w not in stopwords_en and w not in string.punctuation]\n",
        "print(\"\\nüîπ After stop-word & punctuation filtering:\")\n",
        "print(tokens_no_sw)"
      ],
      "metadata": {
        "id": "lqHatu2KN-2i",
        "outputId": "55339f2e-c5e5-452c-b120-9b2947e2de3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lqHatu2KN-2i",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ After stop-word & punctuation filtering:\n",
            "['love', 'natural', 'language', 'processing', ':)', '#nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Stemming: remove the stems e.g. \"ing\"\n",
        "stemmer = PorterStemmer()\n",
        "stemmed = [stemmer.stem(w) for w in tokens_no_sw]\n",
        "print(\"\\nüîπ After stemming:\")\n",
        "print(stemmed)"
      ],
      "metadata": {
        "id": "nCb9dBo_OBU4",
        "outputId": "0e4bb50c-9667-4c24-d431-11295164eafe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nCb9dBo_OBU4",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ After stemming:\n",
            "['love', 'natur', 'languag', 'process', ':)', '#nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1f24c50-8af4-4c63-9e3d-a36cb2160f0a",
      "metadata": {
        "id": "a1f24c50-8af4-4c63-9e3d-a36cb2160f0a"
      },
      "source": [
        "\n",
        "**What‚Äôs happening?**\n",
        "\n",
        "- The tokenizer converts the sentence to lower-case and breaks it into tokens.\n",
        "- Stop-words like \"I\" are removed ‚Äì they carry little meaning in sentiment tasks.\n",
        "- Stemming reduces words to their roots (*processing ‚Üí process*), shrinking your model's vocabulary.\n",
        "\n",
        "This is the backbone of many real NLP pipelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d450553-dac3-4cd7-b74e-e1c0bec41216",
      "metadata": {
        "id": "9d450553-dac3-4cd7-b74e-e1c0bec41216"
      },
      "source": [
        "## 2Ô∏è‚É£ Peek at the Twitter dataset\n",
        "Now let's repeat this using 10k Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae35aed7-bfd5-49cd-b435-c83698c3e994",
      "metadata": {
        "id": "ae35aed7-bfd5-49cd-b435-c83698c3e994"
      },
      "source": [
        "\n",
        "The NLTK `twitter_samples` corpus contains:\n",
        "\n",
        "- **5,000 positive tweets**  \n",
        "- **5,000 negative tweets**\n",
        "\n",
        "Let‚Äôs load and preview it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b770a6a2-9b69-4c6a-b96e-3b6b4dfef235",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b770a6a2-9b69-4c6a-b96e-3b6b4dfef235",
        "outputId": "a58d6d93-5000-40bd-8bca-74daca158198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 5,000 positive tweets\n",
            "‚úÖ Loaded 5,000 negative tweets\n",
            "\n",
            "üî∏ Example positive tweet:\n",
            "@kingsheadgford Love that song! :)\n",
            "\n",
            "üî∏ Example negative tweet:\n",
            "@argon_ramos @SoddersLiger *joins the hugs* I'm sorry to hear Sodders :(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(all_positive_tweets):,} positive tweets\")\n",
        "print(f\"‚úÖ Loaded {len(all_negative_tweets):,} negative tweets\")\n",
        "\n",
        "#Inspect some random tweets\n",
        "print(\"\\nüî∏ Example positive tweet:\")\n",
        "print(random.choice(all_positive_tweets))\n",
        "\n",
        "print(\"\\nüî∏ Example negative tweet:\")\n",
        "print(random.choice(all_negative_tweets))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea89d9c7-7865-4aa3-9444-6d7e022ec1bf",
      "metadata": {
        "id": "ea89d9c7-7865-4aa3-9444-6d7e022ec1bf"
      },
      "source": [
        "## 3Ô∏è‚É£ Wrap it up: a reusable `process_tweet()` function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b41f51-25ec-412d-a1c5-7096aae7a18f",
      "metadata": {
        "id": "e7b41f51-25ec-412d-a1c5-7096aae7a18f"
      },
      "source": [
        "\n",
        "We‚Äôll combine the steps into a helper function you can reuse later. Instead of running each function individually we can just build a function to doing the \"cleaning job\" in one go.\n",
        "\n",
        "This includes:\n",
        "- Lowercasing  \n",
        "- Removing links, handles, and hashtags  \n",
        "- Tokenizing  \n",
        "- Filtering  \n",
        "- Stemming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2fd62603-2524-480f-92b5-a6e250f75140",
      "metadata": {
        "id": "2fd62603-2524-480f-92b5-a6e250f75140"
      },
      "outputs": [],
      "source": [
        "#Let's build the function\n",
        "def process_tweet(tweet: str):\n",
        "    \"\"\"Preprocess a single tweet into cleaned, stemmed tokens.\"\"\"\n",
        "    tweet = tweet.lower()\n",
        "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '', tweet)  # remove links\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)                     # remove @handles\n",
        "    tweet = re.sub(r'#', '', tweet)                         # strip hashtags\n",
        "\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    stopwords_en = stopwords.words('english')\n",
        "    tokens_clean = [tok for tok in tokens if tok not in stopwords_en and tok not in string.punctuation]\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    stems = [stemmer.stem(tok) for tok in tokens_clean]\n",
        "\n",
        "    return stems"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try out our new function on a Tweet"
      ],
      "metadata": {
        "id": "X_YT2qmFOxPD"
      },
      "id": "X_YT2qmFOxPD"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "78e72e0a-d1d9-4e41-80d7-90ba0d9e09c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78e72e0a-d1d9-4e41-80d7-90ba0d9e09c5",
        "outputId": "652835da-d166-410c-ba51-085b51a5ab37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tweet:\n",
            " My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
            "\n",
            "Processed tokens:\n",
            "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '‚Ä¶']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sample = all_positive_tweets[2277]\n",
        "print(\"Original tweet:\\n\", sample)\n",
        "\n",
        "print(\"\\nProcessed tokens:\")\n",
        "print(process_tweet(sample))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629ee9dd",
      "metadata": {
        "id": "629ee9dd"
      },
      "source": [
        "‚ú® *Much cleaner!* You can now use these tokens in classifiers or embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b582f7b-d8ac-492d-9864-075a50c0c8cb",
      "metadata": {
        "id": "6b582f7b-d8ac-492d-9864-075a50c0c8cb"
      },
      "source": [
        "---\n",
        "\n",
        "## üéâ You finished Lesson L1!\n",
        "\n",
        "You're now equipped to:\n",
        "- Clean and tokenize tweets for downstream tasks\n",
        "- Understand the role of stop-word filtering and stemming\n",
        "- Build preprocessing pipelines for larger models\n",
        "\n",
        "üëâ In the next lesson, we‚Äôll use these tokens to build features and train your first classifier!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}