{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc633f31",
   "metadata": {},
   "source": [
    "# Lesson L3 – Logistic Regression for Tweet Sentiment 📈❤️💔\n",
    "\n",
    "Welcome to **Lesson L3** of our Colab‑ready DeepLearning.AI NLP remake!\n",
    "\n",
    "## What you’ll learn\n",
    "* Convert cleaned tweets into **numeric features**  \n",
    "* Train a **Logistic Regression** classifier for sentiment  \n",
    "* **Visualise** tweets in feature‑space and the model’s decision boundary  \n",
    "* Evaluate accuracy & interpret the learned weights  \n",
    "* Experiment live with an **interactive Gradio playground**\n",
    "\n",
    "## Why this matters\n",
    "Getting from *word counts* → *predictions* is the heart of many NLP systems.  \n",
    "Logistic Regression is a surprisingly strong baseline and lays the groundwork for neural networks.\n",
    "\n",
    "## Roadmap\n",
    "1. **Setup & installs** – one cell, ready for Colab  \n",
    "2. **Toy example** – six handmade tweets to see LR end‑to‑end  \n",
    "3. **Real dataset** – 10 k NLTK tweets, build features on the fly  \n",
    "4. **Visualisation** – scatter & decision boundary  \n",
    "5. **Evaluation** – accuracy + confusion matrix  \n",
    "6. **Gradio playground** – paste any text and get a sentiment score  \n",
    "\n",
    "_👉 Let’s dive in!_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🍀 Colab setup – run this first!\n",
    "# Installs pinned to avoid version conflicts with Colab pre‑installs\n",
    "!pip -q install --upgrade \\\n",
    "        \"nltk\" \\\n",
    "        \"wordcloud\" \\\n",
    "        \"numpy>=1.26,<2.1\" \\\n",
    "        \"scikit-learn<1.7\" \\\n",
    "        \"gradio>=4.27.0\" \\\n",
    "        \"websockets>=13,<15\" --progress-bar off\n",
    "\n",
    "import nltk, ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "for resource in ['stopwords', 'punkt', 'twitter_samples']:\n",
    "    nltk.download(resource, quiet=True)\n",
    "\n",
    "print(\"✅ Environment & NLTK corpora ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08216daf",
   "metadata": {},
   "source": [
    "## 1️⃣ Toy example – six mini‑tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def simple_process(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
    "    return [stemmer.stem(w) for w in sentence.split() if w not in stop_words]\n",
    "\n",
    "# Mini sentiment lexicon\n",
    "pos_lex = {'love','great','happy'}\n",
    "neg_lex = {'hate','bad','sad'}\n",
    "\n",
    "def to_features(tokens):\n",
    "    pos_cnt = sum(w in pos_lex for w in tokens)\n",
    "    neg_cnt = sum(w in neg_lex for w in tokens)\n",
    "    return [pos_cnt, neg_cnt]\n",
    "\n",
    "toy_tweets = [\n",
    "    \"I love this!\",\n",
    "    \"This is great and makes me happy\",\n",
    "    \"So happy, great vibes\",\n",
    "    \"I hate this, really bad\",\n",
    "    \"This is sad and bad\",\n",
    "    \"I hate it so much\"\n",
    "]\n",
    "y_toy = np.array([1,1,1,0,0,0])\n",
    "\n",
    "X_toy = np.array([to_features(simple_process(t)) for t in toy_tweets])\n",
    "\n",
    "print(\"Toy feature matrix:\\n\", X_toy)\n",
    "\n",
    "clf_toy = LogisticRegression()\n",
    "clf_toy.fit(X_toy, y_toy)\n",
    "\n",
    "print(\"Toy accuracy:\", clf_toy.score(X_toy, y_toy))\n",
    "\n",
    "# plot decision boundary\n",
    "plt.figure(figsize=(4,4))\n",
    "for label, marker, color in [(1,'o','green'), (0,'x','red')]:\n",
    "    mask = y_toy==label\n",
    "    plt.scatter(X_toy[mask,0], X_toy[mask,1], marker=marker, color=color, label='pos' if label else 'neg', s=80)\n",
    "\n",
    "coef = clf_toy.coef_[0]; intercept = clf_toy.intercept_[0]\n",
    "xs = np.linspace(0,3,100)\n",
    "ys = -(coef[0]*xs + intercept)/coef[1]\n",
    "plt.plot(xs, ys, '--k')\n",
    "plt.xlabel('Positive count'); plt.ylabel('Negative count')\n",
    "plt.xlim(-0.2,3.5); plt.ylim(-0.2,3.5); plt.legend()\n",
    "plt.title(\"Toy decision boundary\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a39263",
   "metadata": {},
   "source": [
    "**What to notice**\n",
    "\n",
    "* Tweets with more *positive cues* sit left of the boundary.  \n",
    "* LR learns weights to separate the two classes with a straight line.  \n",
    "* Coefficients magnitude ≈ feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612cf46",
   "metadata": {},
   "source": [
    "## 2️⃣ Helper functions – inline (no utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_tweet(tweet: str):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'https?://\\S+', '', tweet)\n",
    "    tweet = re.sub(r'[^a-z\\s]', '', tweet)\n",
    "    return [stemmer.stem(w) for w in tweet.split() if w not in stop_words]\n",
    "\n",
    "def build_freqs(tweets, ys):\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\n",
    "    return freqs\n",
    "\n",
    "def tweet_to_xy(tweet, pos_vocab, neg_vocab):\n",
    "    tokens = process_tweet(tweet)\n",
    "    pos_cnt = sum(tok in pos_vocab for tok in tokens)\n",
    "    neg_cnt = sum(tok in neg_vocab for tok in tokens)\n",
    "    return np.array([pos_cnt, neg_cnt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488ea2d",
   "metadata": {},
   "source": [
    "## 3️⃣ Full tweet corpus – build features & train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "import numpy as np\n",
    "\n",
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "tweets = pos_tweets + neg_tweets\n",
    "ys = np.append(np.ones(len(pos_tweets)), np.zeros(len(neg_tweets)))\n",
    "\n",
    "freqs = build_freqs(tweets, ys)\n",
    "\n",
    "# Vocab threshold\n",
    "pos_vocab = {w for (w,y) in freqs if y==1 and freqs[(w,1)] > 5}\n",
    "neg_vocab = {w for (w,y) in freqs if y==0 and freqs[(w,0)] > 5}\n",
    "\n",
    "print(f\"Positive vocab: {len(pos_vocab)} words | Negative vocab: {len(neg_vocab)} words\")\n",
    "\n",
    "X = np.array([tweet_to_xy(t, pos_vocab, neg_vocab) for t in tweets])\n",
    "print(\"Feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3afcad",
   "metadata": {},
   "source": [
    "### Train / test split & model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ys, test_size=0.2, random_state=42, stratify=ys)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_score(y_train, model.predict(X_train)))\n",
    "print(\"Test  accuracy:\", accuracy_score(y_test,  model.predict(X_test)))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, display_labels=['neg','pos'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541b262",
   "metadata": {},
   "source": [
    "### Visualising tweet distribution & decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "sample_idx = np.random.choice(len(X), 2000, replace=False)\n",
    "X_s = X[sample_idx]; y_s = ys[sample_idx]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "for label, marker, col in [(1,'o','limegreen'), (0,'x','crimson')]:\n",
    "    mask = y_s==label\n",
    "    plt.scatter(X_s[mask,0], X_s[mask,1], marker=marker, color=col, label='pos' if label else 'neg', alpha=0.5)\n",
    "\n",
    "coef = model.coef_[0]; intercept=model.intercept_[0]\n",
    "xs = np.linspace(0, X[:,0].max()+2, 100)\n",
    "ys_line = -(coef[0]*xs + intercept)/coef[1]\n",
    "plt.plot(xs, ys_line, '--k', linewidth=2)\n",
    "\n",
    "plt.xlabel('Positive word count'); plt.ylabel('Negative word count')\n",
    "plt.title('Tweet sentiment space')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0, X[:,0].max()+1); plt.ylim(0, X[:,1].max()+1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531143f",
   "metadata": {},
   "source": [
    "**Interpretation tips**\n",
    "\n",
    "* Many tweets contain *no* positive words (x=0) or negative words (y=0); that’s why points hug the axes.  \n",
    "* Adding richer features (bigrams, TF‑IDF) can separate overlapping clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52c2b3",
   "metadata": {},
   "source": [
    "## 4️⃣ Interactive Gradio sentiment tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f043bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from collections import Counter\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    feats = tweet_to_xy(text, pos_vocab, neg_vocab)\n",
    "    prob_pos = float(model.predict_proba([feats])[0][1])\n",
    "    label = \"Positive 😊\" if prob_pos >= 0.5 else \"Negative 😞\"\n",
    "    return {\n",
    "        \"Positive-count\": int(feats[0]),\n",
    "        \"Negative-count\": int(feats[1]),\n",
    "        \"Prob‑positive\": round(prob_pos, 3),\n",
    "        \"Prediction\": label\n",
    "    }\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 🎛️ Sentiment tester (Logistic Regression)\")\n",
    "    txt = gr.Textbox(label=\"Enter tweet text\", lines=3)\n",
    "    out = gr.JSON(label=\"Model output\")\n",
    "    txt.submit(predict_sentiment, txt, out)\n",
    "    gr.Button(\"Run\").click(predict_sentiment, txt, out)\n",
    "\n",
    "# Uncomment the next line when running in Colab\n",
    "# demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88aa810",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "🎉 **You trained, visualised, and deployed a sentiment classifier!**  \n",
    "Try tweaking the vocabulary threshold, adding TF‑IDF, or swapping in a different model to see how performance changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
