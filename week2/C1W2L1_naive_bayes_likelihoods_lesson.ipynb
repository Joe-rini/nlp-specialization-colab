{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dba6c4e",
   "metadata": {},
   "source": [
    "# 📘 C1W2_L1: Naive Bayes Likelihoods – Teaching Version\n",
    "\n",
    "🎯 **Let's build a classifier. First Toy, then real!**\n",
    "\n",
    "In this workbook, our goal is to build a system that can predict whether a Tweet is positive or negative. Like last week’s logistic regression, we’ll keep things simple and interpretable: no word order, no phrasing — just plain counts of which words appear.\n",
    "\n",
    "But instead of learning weights through optimization (like logistic regression), this time we’ll build a model using **Bayes’ Theorem** and **word frequencies**. Think of this as letting probabilities do the talking, based on how often a word appears in positive vs. negative tweets.\n",
    "\n",
    "You’ll see lots of overlap with Week 1’s bag-of-words approach — but the core *math* behind the prediction is different. Let’s dive in!\n",
    "\n",
    "Unlike logistic regression last week, there’s no optimization or gradient descent here — just a lookup-based statistical model derived directly from the labeled data. It’s still “learning,” but it’s more like rule-building from observed frequencie\n",
    "🧠 So is this “learning”?\n",
    "Barely. In the broadest ML sense: yes, because the model's behavior changes depending on what data it sees.\n",
    "\n",
    "But:\n",
    "\n",
    "It’s parametric (small number of parameters: priors and word likelihoods)\n",
    "\n",
    "It’s closed-form (you just calculate values)\n",
    "\n",
    "It’s non-adaptive beyond word frequencies\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 What is Naive Bayes?\n",
    "Naive Bayes is a simple yet powerful classification algorithm based on **Bayes’ Theorem**:\n",
    "\n",
    "\\[ P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)} \\]\n",
    "\n",
    "In our case:\n",
    "- A = a sentiment label (e.g., positive or negative)\n",
    "- B = the tweet’s words\n",
    "\n",
    "The “naive” assumption is that all words in a tweet are **conditionally independent** given the sentiment label.\n",
    "\n",
    "This means we treat \"bad\" and \"dream\" as unrelated — even though \"bad dream\" might have a specific negative meaning together. That’s the simplification — and limitation — of this approach.\n",
    "\n",
    "The classifier works by computing a **log-likelihood score** for each label:\n",
    "\n",
    "\\[ \\text{score} = \\log(P(\\text{label})) + \\sum_{i} \\log(P(\\text{word}_i \\mid \\text{label})) \\]\n",
    "\n",
    "We choose the label with the highest score. This is different from last week, where the score came from a **sigmoid curve fitted by gradient descent**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 How is this similar to last week?\n",
    "- ✅ We still represent tweets using **bag-of-words** (no order, just counts)\n",
    "- ✅ We still want to predict positive vs negative\n",
    "- ✅ We still calculate a score per tweet\n",
    "\n",
    "## 🔍 What’s different this week?\n",
    "- ❌ No learned weights from gradient descent\n",
    "- ✅ We calculate probabilities directly from word frequencies\n",
    "- ✅ We use **log-likelihoods** instead of a sigmoid decision function\n",
    "\n",
    "In short, both methods try to split tweets by some kind of score — but how that score is **calculated** is different.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 1. Setup & Downloads\n",
    "We'll begin by installing dependencies and loading some Twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio\n",
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba8b58",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "C1W2_L1_Naive_Bayes_Teaching.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
