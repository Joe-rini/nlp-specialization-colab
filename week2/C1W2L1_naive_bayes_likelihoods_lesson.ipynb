{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8dba6c4e",
      "metadata": {
        "id": "8dba6c4e"
      },
      "source": [
        "# üìò C1W2_L1: Naive Bayes Likelihoods ‚Äì Teaching Version\n",
        "\n",
        "In this workbook, our goal is to build a system that can predict whether a Tweet is positive or negative using the Naive Bayes approach. Like last week‚Äôs logistic regression, we‚Äôll keep things simple and interpretable: no word order, no phrasing ‚Äî just plain counts of which words appear.\n",
        "\n",
        "But instead of learning weights through optimization (like logistic regression), this time we‚Äôll build a model using **Bayes‚Äô Theorem** and **word frequencies**.\n",
        "\n",
        "You‚Äôll see lots of overlap with Week 1‚Äôs bag-of-words approach ‚Äî but the core *math* behind the prediction is different. Let‚Äôs dive in!\n",
        "\n",
        "Unlike logistic regression last week, there‚Äôs no optimization or gradient descent here ‚Äî just a lookup-based statistical model derived directly from the labeled data.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Quick Intro: What is Naive Bayes?\n",
        "Naive Bayes is a simple yet powerful classification algorithm based on **Bayes‚Äô Theorem**:\n",
        "\n",
        "The ‚Äúnaive‚Äù assumption is that all words in a tweet are **conditionally independent**, given the sentiment label (whether the Tweet is Positive or Negative).\n",
        "\n",
        "All we are doing is figuring out likelihood a word is positive or negative given that the Tweet is positive or negative. Once we have those likelihoods for all words in our dictionary we can predict whether new Tweets are positive or negative.\n",
        "\n",
        "---\n",
        "\n",
        "## üîß 1. Setup & Downloads\n",
        "Just like last week, before starting on the code examples, let's load some of the packages and the Tweet samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "effbe7bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "effbe7bd",
        "outputId": "a62b8aab-25b0-4578-ea4e-b2bb5c2acc5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c322cc73",
      "metadata": {
        "id": "c322cc73"
      },
      "source": [
        "---\n",
        "\n",
        "## Import Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "94b36ef6",
      "metadata": {
        "id": "94b36ef6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• 2. Toy Example\n",
        "Like last week, let‚Äôs build a full, end-to-end Toy Example first to lock-in the concepts before moving on to the 10k Tweet example. We'll build a Naive Bayes model using 6 manually written Tweets.\n",
        "\n",
        "We'll follow the following simple steps:\n",
        "1. Hand create 6 Tweets and declard them positive or negative.\n",
        "2. Pre-process the Tweets: clean, remove stop words\n",
        "3. Count how often the remaining words occur in the positive and negative Tweets.\n",
        "4. Calculate a ratio using these counts.\n",
        "\n",
        "\n",
        "First let's familiarize ourselves with the data a bit.\n",
        "\n"
      ],
      "metadata": {
        "id": "ay85Erh0kEK9"
      },
      "id": "ay85Erh0kEK9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Toy tweets and labels\n",
        "toy_tweets = [\n",
        "    \"I love this product\",           # pos\n",
        "    \"Very happy with my purchase\",  # pos\n",
        "    \"Best thing ever!\",             # pos\n",
        "    \"I hate this thing\",            # neg\n",
        "    \"Terrible experience\",          # neg\n",
        "    \"Horrible product\"              # neg\n",
        "]\n",
        "toy_labels = [1, 1, 1, 0, 0, 0]  # 1 = positive, 0 = negative\n",
        "\n",
        "# Step 2: Count word frequencies\n",
        "freqs = count_tweets({}, toy_tweets, toy_labels)\n",
        "\n",
        "# Step 3: Extract vocabulary and print it\n",
        "vocab = set([pair[0] for pair in freqs])\n",
        "V = len(vocab)\n",
        "\n",
        "#Print the cleared extracted works from the Tweets\n",
        "for i, tweet in enumerate(toy_tweets):\n",
        "    print(f\"Original: {tweet}\")\n",
        "    print(f\"Cleaned:  {process_tweet(tweet)}\\n\")\n",
        "\n",
        "#print the list of all extracted and the vocab count\n",
        "print(\"üìö Vocabulary (sorted):\")\n",
        "print(sorted(vocab))\n",
        "print(f\"\\nüî¢ Vocabulary size: {V}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gnOrtLBkQjQ",
        "outputId": "6a7fcfd6-36c1-4733-f307-51a8f3b4a94a"
      },
      "id": "7gnOrtLBkQjQ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: I love this product\n",
            "Cleaned:  ['love', 'product']\n",
            "\n",
            "Original: Very happy with my purchase\n",
            "Cleaned:  ['happy', 'purchase']\n",
            "\n",
            "Original: Best thing ever!\n",
            "Cleaned:  ['best', 'thing', 'ever']\n",
            "\n",
            "Original: I hate this thing\n",
            "Cleaned:  ['hate', 'thing']\n",
            "\n",
            "Original: Terrible experience\n",
            "Cleaned:  ['terrible', 'experience']\n",
            "\n",
            "Original: Horrible product\n",
            "Cleaned:  ['horrible', 'product']\n",
            "\n",
            "üìö Vocabulary (sorted):\n",
            "['best', 'ever', 'experience', 'happy', 'hate', 'horrible', 'love', 'product', 'purchase', 'terrible', 'thing']\n",
            "\n",
            "üî¢ Vocabulary size: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And quickly, how many unique words from the dictionary are in both positive and negative."
      ],
      "metadata": {
        "id": "GV0myz_X_XsJ"
      },
      "id": "GV0myz_X_XsJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of words in each class (positive & negative Tweets)\n",
        "N_pos = sum([freqs.get((word, 1), 0) for word in vocab])\n",
        "N_neg = sum([freqs.get((word, 0), 0) for word in vocab])\n",
        "\n",
        "print(f\"üü¢ Total words in positive tweets: {N_pos}\")\n",
        "print(f\"üî¥ Total words in negative tweets: {N_neg}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKOm__PGm5F1",
        "outputId": "429270ab-1ac2-42d9-9dc9-c04bfc9f714c"
      },
      "id": "dKOm__PGm5F1",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üü¢ Total words in positive tweets: 7\n",
            "üî¥ Total words in negative tweets: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure out the proportion of positive to negative Tweets in the dataset."
      ],
      "metadata": {
        "id": "ktCfmDGo_jLm"
      },
      "id": "ktCfmDGo_jLm"
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine the ratio of positive to negative Tweets. This log prior gives you the base bias of the classifier before any words are seen.\n",
        "#In our example this is 0, since we have an equal number of positive and negative Tweets.\n",
        "\n",
        "logprior = np.log(sum(toy_labels) / (len(toy_labels) - sum(toy_labels)))\n",
        "\n",
        "print(f\"\\n‚öñÔ∏è Log Prior: {logprior:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diXbwXWLnn3W",
        "outputId": "74fdf7e0-cd39-4b68-f73d-c603adac0355"
      },
      "id": "diXbwXWLnn3W",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öñÔ∏è Log Prior: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have taking a look at the data, let's calculate the Log-Liklihood of each word being positive or negative.\n",
        "\n",
        "We'll produce a summary table that provides a crystal clear recap of output. Be sure to familiarize yourself with what we have generated and how it all links to the original 6 Tweets."
      ],
      "metadata": {
        "id": "c-ecJadKAVPX"
      },
      "id": "c-ecJadKAVPX"
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Compute Log-Likelihood for Each Word: This tells you how strongly each word tilts the prediction toward positive or negative.\n",
        "\n",
        "loglikelihood = {}\n",
        "\n",
        "for word in vocab:\n",
        "    freq_pos = freqs.get((word, 1), 0)\n",
        "    freq_neg = freqs.get((word, 0), 0)\n",
        "\n",
        "    # Laplace smoothing\n",
        "    p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "    p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "    # Log-likelihood ratio\n",
        "    loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "    print(f\"üî§ '{word}': log(P(word|pos)/P(word|neg)) = {loglikelihood[word]:.4f}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# List to store each row\n",
        "rows = []\n",
        "\n",
        "# Loop through vocabulary\n",
        "for word in sorted(vocab):\n",
        "    freq_pos = freqs.get((word, 1), 0)\n",
        "    freq_neg = freqs.get((word, 0), 0)\n",
        "\n",
        "    p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "    p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "    llr = np.log(p_w_pos / p_w_neg)\n",
        "    loglikelihood[word] = llr\n",
        "\n",
        "    # Append row for DataFrame\n",
        "    rows.append({\n",
        "        \"Word\": word,\n",
        "        \"Pos Count\": freq_pos,\n",
        "        \"Neg Count\": freq_neg,\n",
        "        \"P(word|pos)\": round(p_w_pos, 4),\n",
        "        \"P(word|neg)\": round(p_w_neg, 4),\n",
        "        \"Log-Likelihood\": round(llr, 4)\n",
        "    })\n",
        "\n",
        "# Create and display table\n",
        "df_likelihood = pd.DataFrame(rows)\n",
        "df_likelihood = df_likelihood.sort_values(\"Log-Likelihood\", ascending=False)\n",
        "df_likelihood.reset_index(drop=True, inplace=True)\n",
        "df_likelihood\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "o6zpguDNpXSi",
        "outputId": "fcfe7fdf-aa82-4fda-c4f5-3246a6a8498f"
      },
      "id": "o6zpguDNpXSi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî§ 'hate': log(P(word|pos)/P(word|neg)) = -0.7503\n",
            "üî§ 'horrible': log(P(word|pos)/P(word|neg)) = -0.7503\n",
            "üî§ 'purchase': log(P(word|pos)/P(word|neg)) = 0.6360\n",
            "üî§ 'ever': log(P(word|pos)/P(word|neg)) = 0.6360\n",
            "üî§ 'terrible': log(P(word|pos)/P(word|neg)) = -0.7503\n",
            "üî§ 'experience': log(P(word|pos)/P(word|neg)) = -0.7503\n",
            "üî§ 'thing': log(P(word|pos)/P(word|neg)) = -0.0572\n",
            "üî§ 'love': log(P(word|pos)/P(word|neg)) = 0.6360\n",
            "üî§ 'happy': log(P(word|pos)/P(word|neg)) = 0.6360\n",
            "üî§ 'product': log(P(word|pos)/P(word|neg)) = -0.0572\n",
            "üî§ 'best': log(P(word|pos)/P(word|neg)) = 0.6360\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Word  Pos Count  Neg Count  P(word|pos)  P(word|neg)  Log-Likelihood\n",
              "0         best          1          0       0.1111       0.0588          0.6360\n",
              "1         ever          1          0       0.1111       0.0588          0.6360\n",
              "2        happy          1          0       0.1111       0.0588          0.6360\n",
              "3     purchase          1          0       0.1111       0.0588          0.6360\n",
              "4         love          1          0       0.1111       0.0588          0.6360\n",
              "5        thing          1          1       0.1111       0.1176         -0.0572\n",
              "6      product          1          1       0.1111       0.1176         -0.0572\n",
              "7   experience          0          1       0.0556       0.1176         -0.7503\n",
              "8         hate          0          1       0.0556       0.1176         -0.7503\n",
              "9     horrible          0          1       0.0556       0.1176         -0.7503\n",
              "10    terrible          0          1       0.0556       0.1176         -0.7503"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a5dba0d-e520-42eb-a0a9-c8ba8358be51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Pos Count</th>\n",
              "      <th>Neg Count</th>\n",
              "      <th>P(word|pos)</th>\n",
              "      <th>P(word|neg)</th>\n",
              "      <th>Log-Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>best</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.0588</td>\n",
              "      <td>0.6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ever</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.0588</td>\n",
              "      <td>0.6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happy</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.0588</td>\n",
              "      <td>0.6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>purchase</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.0588</td>\n",
              "      <td>0.6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>love</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.0588</td>\n",
              "      <td>0.6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>thing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1176</td>\n",
              "      <td>-0.0572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>product</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1176</td>\n",
              "      <td>-0.0572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>experience</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.1176</td>\n",
              "      <td>-0.7503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hate</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.1176</td>\n",
              "      <td>-0.7503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>horrible</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.1176</td>\n",
              "      <td>-0.7503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>terrible</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.1176</td>\n",
              "      <td>-0.7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a5dba0d-e520-42eb-a0a9-c8ba8358be51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a5dba0d-e520-42eb-a0a9-c8ba8358be51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a5dba0d-e520-42eb-a0a9-c8ba8358be51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e6435d2c-c4f9-490f-9531-2ca2d4b88012\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6435d2c-c4f9-490f-9531-2ca2d4b88012')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e6435d2c-c4f9-490f-9531-2ca2d4b88012 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d9ac76d9-080c-488a-b412-e7186d323085\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_likelihood')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d9ac76d9-080c-488a-b412-e7186d323085 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_likelihood');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_likelihood",
              "summary": "{\n  \"name\": \"df_likelihood\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"thing\",\n          \"best\",\n          \"horrible\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P(word|pos)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02800113634057798,\n        \"min\": 0.0556,\n        \"max\": 0.1111,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0556,\n          0.1111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P(word|neg)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030707298510585096,\n        \"min\": 0.0588,\n        \"max\": 0.1176,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.1176,\n          0.0588\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Log-Likelihood\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.654251251987547,\n        \"min\": -0.7503,\n        \"max\": 0.636,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.636,\n          -0.0572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that we have built the model, let's test it out on a new Tweet"
      ],
      "metadata": {
        "id": "4W2ZPzvZK8mx"
      },
      "id": "4W2ZPzvZK8mx"
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "    words = process_tweet(tweet)\n",
        "    score = logprior\n",
        "    for word in words:\n",
        "        if word in loglikelihood:\n",
        "            score += loglikelihood[word]\n",
        "    return score\n",
        "\n",
        "test_tweet = \"I hate this product\"\n",
        "score = naive_bayes_predict(test_tweet, logprior, loglikelihood)\n",
        "sentiment = \"Positive üòÄ\" if score > 0 else \"Negative üòû\"\n",
        "print(f\"\\nüß™ Test Tweet: '{test_tweet}' ‚Üí Score: {score:.2f} ‚Üí {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sub-R0uqptP9",
        "outputId": "e55e7989-7204-445c-f501-e6a294c03e6e"
      },
      "id": "Sub-R0uqptP9",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Test Tweet: 'I hate this product' ‚Üí Score: -0.81 ‚Üí Negative üòû\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a353ffbe",
      "metadata": {
        "id": "a353ffbe"
      },
      "source": [
        "---\n",
        "\n",
        "## üí¨ 3. On to the production example: Let's build Naive Bayes from the 10k Tweet sample\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6655fb17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6655fb17",
        "outputId": "c3e70442-004f-4cf8-d0da-0e2759fbfcfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample positive tweet:\n",
            "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n"
          ]
        }
      ],
      "source": [
        "#Step 1: Load and take a look at the Teet data\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "print(\"Sample positive tweet:\")\n",
        "print(all_positive_tweets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec1bca2",
      "metadata": {
        "id": "2ec1bca2"
      },
      "source": [
        "---\n",
        "\n",
        "## üßπ 3a. Clean & Preprocess the Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "29f1c1db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29f1c1db",
        "outputId": "fe22b172-4a91-4468-91f3-8dc1e821ad94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hopeless', 'tmr', ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "stopwords_english = stopwords.words('english')\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    clean = [word for word in tokens if word not in stopwords_english and word not in string.punctuation]\n",
        "    return clean\n",
        "\n",
        "# Try on a sample\n",
        "process_tweet(all_negative_tweets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c723ffa0",
      "metadata": {
        "id": "c723ffa0"
      },
      "source": [
        "---\n",
        "\n",
        "## üìä 3b. Count Word Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4ce52b53",
      "metadata": {
        "id": "4ce52b53"
      },
      "outputs": [],
      "source": [
        "def count_tweets(freq_dict, tweets, labels):\n",
        "    for label, tweet in zip(labels, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, label)\n",
        "            freq_dict[pair] = freq_dict.get(pair, 0) + 1\n",
        "    return freq_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2781d2",
      "metadata": {
        "id": "9c2781d2"
      },
      "source": [
        "---\n",
        "\n",
        "## üìê 4. Now let's \"train\" the Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67c3723",
      "metadata": {
        "id": "e67c3723"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    loglikelihood = {}\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "    N_pos = N_neg = 0\n",
        "    for pair in freqs:\n",
        "        if pair[1] == 1:\n",
        "            N_pos += freqs[pair]\n",
        "        else:\n",
        "            N_neg += freqs[pair]\n",
        "    D = len(train_y)\n",
        "    D_pos = sum(train_y)\n",
        "    D_neg = D - D_pos\n",
        "    logprior = np.log(D_pos / D_neg)\n",
        "    for word in vocab:\n",
        "        freq_pos = freqs.get((word, 1), 0)\n",
        "        freq_neg = freqs.get((word, 0), 0)\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
        "    return logprior, loglikelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e99b1a5",
      "metadata": {
        "id": "3e99b1a5"
      },
      "source": [
        "---\n",
        "\n",
        "## üèóÔ∏è 4a. Build and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78131ce",
      "metadata": {
        "id": "e78131ce"
      },
      "outputs": [],
      "source": [
        "train_x = all_positive_tweets[:4000] + all_negative_tweets[:4000]\n",
        "train_y = np.append(np.ones(4000), np.zeros(4000))\n",
        "\n",
        "freqs = count_tweets({}, train_x, train_y)\n",
        "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe7a1ad",
      "metadata": {
        "id": "dbe7a1ad"
      },
      "source": [
        "---\n",
        "\n",
        "## üîÆ 5. Let's Predict Some New Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd63969",
      "metadata": {
        "id": "5dd63969"
      },
      "outputs": [],
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "    words = process_tweet(tweet)\n",
        "    score = logprior\n",
        "    for word in words:\n",
        "        if word in loglikelihood:\n",
        "            score += loglikelihood[word]\n",
        "    return score\n",
        "\n",
        "# Try a test tweet\n",
        "tweet = \"Today is awesome!\"\n",
        "print(f\"Score: {naive_bayes_predict(tweet, logprior, loglikelihood):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0f9422",
      "metadata": {
        "id": "bc0f9422"
      },
      "source": [
        "---\n",
        "\n",
        "## üìä 6. Visualize Influential Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd732c8b",
      "metadata": {
        "id": "bd732c8b"
      },
      "outputs": [],
      "source": [
        "def plot_loglikelihoods(loglikelihood):\n",
        "    top_words = sorted(loglikelihood.items(), key=lambda x: abs(x[1]), reverse=True)[:20]\n",
        "    words, vals = zip(*top_words)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(x=list(vals), y=list(words))\n",
        "    plt.title(\"Most Influential Words\")\n",
        "    plt.xlabel(\"Log-likelihood\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_loglikelihoods(loglikelihood)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "C1W2_L1_Naive_Bayes_Teaching.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}