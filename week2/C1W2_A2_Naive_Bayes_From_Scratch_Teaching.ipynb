{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0dec00-cbd3-4f6e-a135-d2ef619d569a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment A2 – Build Naïve Bayes from Scratch 🔧🪄\n",
    "\n",
    "Welcome to your second assignment in Week 2! This notebook takes you beyond visualization – now **you'll actually implement Naïve Bayes yourself**.\n",
    "\n",
    "---\n",
    "\n",
    "### 👨‍🔬 What you’ll do\n",
    "* Preprocess and clean tweet data using NLTK.\n",
    "* Implement training logic for Naïve Bayes using log-likelihoods and Laplace smoothing.\n",
    "* Predict sentiment using your model.\n",
    "* Inspect influential words with odds ratios.\n",
    "* Explore your model interactively with a Gradio-powered UI.\n",
    "\n",
    "### 📌 What's special\n",
    "This notebook is **autograder-compatible** with the Coursera version. If your local tests pass, **you’ll pass the official grader**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824fe122-ffd1-4497-bc21-3c2ddb888f91",
   "metadata": {},
   "source": [
    "## 🍀 Step 0 – Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1983a-8963-4411-8bd0-3de6ab10326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install --upgrade nltk numpy>=1.26,<2.1 gradio>=4.27.0 websockets>=13,<15 --progress-bar off\n",
    "\n",
    "import nltk, ssl, warnings; warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "for res in ['stopwords','punkt','twitter_samples']:\n",
    "    nltk.download(res, quiet=True)\n",
    "print('✅ Environment ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55242bde-8d12-4d22-abbe-833753e84130",
   "metadata": {},
   "source": [
    "## 1️⃣ Helper functions (provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7b2f8-9ded-4e18-b158-710f94720087",
   "metadata": {},
   "source": [
    "These functions clean and process tweets, and help track word-label counts:\n",
    "\n",
    "- `process_tweet(tweet)` – normalizes, removes stop-words and stems.\n",
    "- `count_tweets(result, tweets, ys)` – builds a frequency dictionary.\n",
    "- `lookup(freqs, word, label)` – helper to count how often a word appears with a specific label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58ef31-494c-4ac6-9522-236c5bb302e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, re, random, math\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "stemmer, stop_words = PorterStemmer(), set(stopwords.words('english'))\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'https?://\\S+','',tweet)\n",
    "    tweet = re.sub(r'[^a-z\\s]','',tweet)\n",
    "    return [stemmer.stem(w) for w in tweet.split() if w not in stop_words]\n",
    "\n",
    "def count_tweets(result, tweets, ys):\n",
    "    for y,t in zip(ys, tweets):\n",
    "        for w in process_tweet(t):\n",
    "            pair = (w,y)\n",
    "            result[pair] = result.get(pair, 0) + 1\n",
    "    return result\n",
    "\n",
    "def lookup(freqs, word, label):\n",
    "    return freqs.get((word, label), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c3ff5-a305-4488-aecc-b2795425b290",
   "metadata": {},
   "source": [
    "## 2️⃣ Load tweet data & train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55737ec6-a95f-49c1-be9a-267ba7f958ce",
   "metadata": {},
   "source": [
    "We use NLTK's pre-labeled Twitter dataset:\n",
    "\n",
    "- **5,000 positive** tweets  \n",
    "- **5,000 negative** tweets\n",
    "\n",
    "We’ll shuffle and split into **80% training** / **20% test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db3d5e-84a0-4d68-825c-8dc7cc11c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = twitter_samples.strings('positive_tweets.json')\n",
    "neg = twitter_samples.strings('negative_tweets.json')\n",
    "tweets = pos + neg\n",
    "ys = np.array([1]*len(pos) + [0]*len(neg))\n",
    "\n",
    "random.seed(0)\n",
    "idx = list(range(len(tweets)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "tweets = [tweets[i] for i in idx]\n",
    "ys = ys[idx]\n",
    "\n",
    "split = int(0.8 * len(tweets))\n",
    "tweets_tr, tweets_te = tweets[:split], tweets[split:]\n",
    "ys_tr, ys_te = ys[:split], ys[split:]\n",
    "\n",
    "print(len(tweets_tr), 'train,', len(tweets_te), 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b509b-a018-403b-8d78-9e3006665590",
   "metadata": {},
   "source": [
    "## 3️⃣ Implement Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b20600-c458-432c-b06e-3b67aba371cb",
   "metadata": {},
   "source": [
    "Now it’s your turn to implement:\n",
    "\n",
    "- `train_naive_bayes`: builds the logprior and loglikelihood from data.\n",
    "- `predict_sentiment`: scores new tweets using your trained model.\n",
    "\n",
    "Use Laplace smoothing and work in log space to avoid underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad67164-c507-4b52-87c3-e4cbc9c198ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNQ_C1\n",
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    \"\"\"Returns logprior, loglikelihood dict.\"\"\"\n",
    "    loglikelihood = {}\n",
    "    vocab = {w for (w,_) in freqs.keys()}\n",
    "    V = len(vocab)\n",
    "    N_pos = N_neg = 0\n",
    "    for pair,c in freqs.items():\n",
    "        if pair[1]==1:\n",
    "            N_pos += c\n",
    "        else:\n",
    "            N_neg += c\n",
    "    D = len(train_y)\n",
    "    D_pos = (train_y==1).sum(); D_neg = (train_y==0).sum()\n",
    "    logprior = math.log(D_pos) - math.log(D_neg)\n",
    "    for w in vocab:\n",
    "        f_pos = freqs.get((w,1),0)\n",
    "        f_neg = freqs.get((w,0),0)\n",
    "        p_w_pos = (f_pos+1)/(N_pos+V)\n",
    "        p_w_neg = (f_neg+1)/(N_neg+V)\n",
    "        loglikelihood[w] = math.log(p_w_pos/p_w_neg)\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf2d74-efea-46f6-b1c5-ae4cb325981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNQ_C2\n",
    "def predict_sentiment(tweet, logprior, loglikelihood):\n",
    "    words = process_tweet(tweet)\n",
    "    score = logprior\n",
    "    for w in words:\n",
    "        if w in loglikelihood:\n",
    "            score += loglikelihood[w]\n",
    "    return 1 if score > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4391d1-45ec-43e3-8e64-81e0ff772d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNQ_C3\n",
    "def get_ratio(freqs, word):\n",
    "    pos = freqs.get((word,1), 0)\n",
    "    neg = freqs.get((word,0), 0)\n",
    "    return (pos + 1) / (neg + 1)\n",
    "\n",
    "### UNQ_C4\n",
    "def get_words_by_threshold(freqs, label, threshold):\n",
    "    out = {}\n",
    "    for w in {w for w,_ in freqs.keys()}:\n",
    "        ratio = get_ratio(freqs, w)\n",
    "        if label == 1 and ratio >= threshold:\n",
    "            out[w] = ratio\n",
    "        elif label == 0 and ratio <= 1/threshold:\n",
    "            out[w] = ratio\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1083ef-656d-42f2-aae3-6bf6420b723f",
   "metadata": {},
   "source": [
    "## 4️⃣ Train & Evaluate Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a08d7de-b504-4ead-b4c4-501e64c90d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = count_tweets({}, tweets_tr, ys_tr)\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, tweets_tr, ys_tr)\n",
    "\n",
    "y_hat = [predict_sentiment(t, logprior, loglikelihood) for t in tweets_te]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print('Test accuracy:', accuracy_score(ys_te, y_hat))\n",
    "print(classification_report(ys_te, y_hat, target_names=['neg','pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59569750-e5d9-4a6e-a985-a433028f157d",
   "metadata": {},
   "source": [
    "## ✅ Local Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b124f3d-efb8-43fb-9553-5423df2ccf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predict_sentiment(\"I love it\", logprior, loglikelihood) in [0,1]\n",
    "assert abs(get_ratio(freqs,'love') - ((freqs.get(('love',1),0)+1)/(freqs.get(('love',0),0)+1))) < 1e-9\n",
    "print('Local checks passed ✔️')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2629fd4-8241-45ed-bc61-4816beadf1bf",
   "metadata": {},
   "source": [
    "## 🧪 Gradio: Interactive Sentiment Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e77f9-526f-4e6b-ad33-d021fddab157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr, numpy as np, math\n",
    "\n",
    "def classify(text):\n",
    "    words = process_tweet(text)\n",
    "    score = logprior + sum(loglikelihood.get(w,0) for w in words)\n",
    "    prob = 1 / (1 + math.exp(-score))\n",
    "    return {\n",
    "        'Prob‑positive': round(prob, 3),\n",
    "        'Prediction': 'Positive 😊' if prob >= 0.5 else 'Negative 😞'\n",
    "    }\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown('### 🔍 Naïve Bayes sentiment tester')\n",
    "    txt = gr.Textbox(lines=3)\n",
    "    out = gr.JSON()\n",
    "    txt.submit(classify, txt, out)\n",
    "    gr.Button('Run').click(classify, txt, out)\n",
    "\n",
    "# Uncomment this to run:\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39757ef9-2c0a-46de-af8a-39e12ee89c56",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎓 You did it!\n",
    "\n",
    "You implemented Naïve Bayes from scratch, trained it on real tweets, interpreted odds ratios, and built a live demo.\n",
    "\n",
    "### Next steps\n",
    "- Use `get_words_by_threshold` to explore the most opinionated words.\n",
    "- Try replacing the dataset with your own texts or product reviews.\n",
    "- Extend the Gradio UI with visual plots or confidence bars!\n",
    "\n",
    "Happy modeling 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
